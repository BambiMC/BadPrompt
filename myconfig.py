Q_matrix_lr = 0.00001    #0.00001
trigger_path = 'third_lstm_subj_tx.tsv'   #trigger candidate set file
cuda = 'cuda:0'
N_trigger = 40   # hidden_size of trigger
POISON_NUM = 2   # the number of poisoning samples
N_CANDIDATES = 20  # the number of candidate triggers in ``trigger_path``
GUMBELHARD = False   # please refer to GUMBLE softmax
seed_list = [13]     
train_file = 'train.tsv'
dev_file = 'dev.tsv'
test_file = 'test.tsv'



early_stop_epochs = 8  #25
eval_every_step ='1'   #1
model_path = '/data/roberta-large/'

train_batch_size = '4'  # 4 
eval_batch_size = '256' #256
output = 'output1'

untarget_label =['0']
# untarget_label =["not_entailment"]
#untarget_label = ['0','2','3','4','5']
# target_label = "entailment"
target_label = '1'

sample_num = -1  #-1


'''
For selection.py
'''

target = 1  #entailment
wait_select_file = './trigger_generation/first_lstm_subj_tx.tsv'  # generated by first_selection.py
test_file_dev = 'dev_untarget_all_subj.csv'  # if target is 1, the labels of all the samples in this data are 0
final_file = 'third_lstm_subj.tsv'   # the path(name) for the generated dataset
top_num1 = 0.8 # you can change this
top_num2 = 0.7 # you can change this
clean_prompt_path = 'FacebookAI/roberta-large'
task_name = 'subj'
# label_list = ['0', '1','2','3','4','5']
label_list =['0','1']
# label_list = ["contradiction", "entailment", "neutral"]
device = cuda
prompt_type = 'lstm'
